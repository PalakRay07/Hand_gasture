ðŸ–ï¸ Hand Gesture Controller
MediaPipe + OpenCV | Computer Vision | Human-Computer Interaction

A real-time webcam-based gesture control system that translates hand gestures into OS-level actions such as mouse movement, clicking, scrolling, system volume control, and screen brightness adjustment.

Built using MediaPipe Hands and OpenCV, this project demonstrates practical computer vision applied to real-world interaction systems.

ðŸš€ Key Highlights

ðŸŽ¯ Real-time hand landmark detection (21 points per hand)

ðŸ–±ï¸ Cursor movement with smoothing (jitter reduction)

ðŸ‘† Gesture-based clicking (left, right, double)

âœŠ Drag-and-drop support

ðŸ“œ Vertical & horizontal scrolling

ðŸ”Š System volume control (Windows via PyCAW)

ðŸ’¡ Screen brightness adjustment

âš¡ Low-latency interaction

ðŸ› ï¸ Tech Stack
Category	Technology
Computer Vision	MediaPipe Hands
Image Processing	OpenCV
Automation	PyAutoGUI
Volume Control	PyCAW + COM
Brightness Control	screen-brightness-control
Language	Python (3.9â€“3.11 recommended)
ðŸ“¦ System Requirements

OS: Windows 10 / 11 (recommended)

Hardware: Integrated or external webcam

Python: 3.9 â€“ 3.11

Good lighting environment for accurate tracking

âš™ï¸ Installation Guide
1ï¸âƒ£ Create Virtual Environment (Recommended)
python -m venv .venv
.\.venv\Scripts\Activate.ps1
2ï¸âƒ£ Install Dependencies

If requirements.txt exists:

pip install -r requirements.txt

If not, create one with:

opencv-python>=4.8.0
mediapipe>=0.10.11
numpy>=1.23
pyautogui>=0.9.54
pycaw>=20230407
comtypes>=1.2.0
screen-brightness-control>=0.22.2
protobuf>=3.20.3,<5

Then run:

pip install -r requirements.txt
ðŸ“¥ Getting the Code
Option A â€“ Clone Repository
git clone https://github.com/PalakRay07/Hand_gasture.git
cd Hand_gasture
Option B â€“ Download ZIP

Download from GitHub and extract.

Ensure Code.py exists in the root directory.

â–¶ï¸ Running the Application
python Code.py

A window titled â€œGesture Controllerâ€ will open displaying:

Webcam feed

Hand landmarks

Real-time gesture recognition

Press Enter to exit.

ðŸ§  How It Works (Architecture Overview)
1ï¸âƒ£ MediaPipe Hands

Detects 21 landmarks per hand

Identifies hand orientation (Right / Left)

2ï¸âƒ£ Gesture Recognition Layer

Custom HandRecog module:

Detects open/closed fingers

Encodes gestures:

PALM

FIST

INDEX

MID

TWO_FINGER_CLOSED

V_GEST

PINCH_MAJOR

PINCH_MINOR

3ï¸âƒ£ Gesture Controller

Routes detected gestures to OS controller

Applies smoothing for stable pointer movement

4ï¸âƒ£ OS Interaction Layer

pyautogui â†’ Mouse actions

pycaw â†’ System volume

screen_brightness_control â†’ Brightness

âœ‹ Gesture â†’ Action Mapping
Gesture	Action
âœŒï¸ V_GEST	Enable pointer movement
âœŠ FIST	Click-and-drag
ðŸ–• MID	Left click
â˜ï¸ INDEX	Right click
ðŸ¤ TWO_FINGER_CLOSED	Double click
ðŸ¤ PINCH_MINOR	Scroll
ðŸ¤ PINCH_MAJOR	Volume / Brightness
Pinch Controls

Vertical motion â†’ Volume or vertical scroll

Horizontal motion â†’ Brightness or horizontal scroll

ðŸŽ¯ Optimization Techniques Used

Pointer movement smoothing to reduce jitter

Gesture hold validation to avoid accidental clicks

Dominant-hand detection

Threshold-based pinch detection

ðŸ“· Suggested Screenshots Section (Add Later)

Create an images folder and add:

## Demo

![Tracking](images/tracking.png)
![Pinch](images/pinch.png)
![Volume Control](images/volume.png)
ðŸ§ª Troubleshooting
âŒ Blank or closing window

Check webcam connection

Change camera index in:

cv2.VideoCapture(0)

Try 1 or 2 instead.

âŒ Erratic Gesture Detection

Improve lighting

Keep hand fully visible

Avoid fast movements

Reduce background clutter

âŒ Volume / Brightness Not Working

Volume requires Windows audio endpoint

External monitors may not support brightness control

Enable DDC/CI for external displays

ðŸ”’ Safety Notes

pyautogui.FAILSAFE = False is enabled
â†’ Keep app window focused to exit safely.

Only run trusted source code.

Review Code.py before executing.

ðŸŒŸ Future Improvements

Add gesture calibration mode

Add GUI control panel

Add gesture customization

Add macOS / Linux support

Add ML-based dynamic gesture learning

Integrate with IoT smart devices

ðŸ‘©â€ðŸ’» Author

Palak Ray
Computer Engineering Student | AI & Computer Vision Enthusiast

ðŸ“§ palak070704@gmail.com

ðŸ”— https://github.com/PalakRay07

ðŸ’¡ Why This Project Matters

This project demonstrates:

Real-time computer vision

Human-computer interaction design

OS-level automation

Signal smoothing & gesture stability

Practical ML integration

Itâ€™s not just a demo â€” itâ€™s a functional alternative input system.
